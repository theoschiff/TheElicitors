{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c247cd",
   "metadata": {},
   "source": [
    "## This is for creating and splitting the Poetry dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c077f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"DanFosing/public-domain-poetry\")\n",
    "dataset_df = pd.DataFrame(dataset[\"train\"])\n",
    "dataset_df = dataset_df[[\"Author\", \"Title\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bca82034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_poem_lines(poem, ratio=1/3):\n",
    "    lines = poem.splitlines()\n",
    "    split_idx = max(1, int(len(lines) * ratio))\n",
    "    start = \"\\n\".join(lines[:split_idx])\n",
    "    end = \"\\n\".join(lines[split_idx:])\n",
    "    return pd.Series([start, end])\n",
    "\n",
    "dataset_df[[\"poem_start\", \"poem_end\"]] = dataset_df[\"text\"].apply(split_poem_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80658146",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.drop(columns=[\"text\"], inplace=True)\n",
    "dataset_df.rename(columns={\"Author\": \"author\", \"Title\": \"title\"}, inplace=True)\n",
    "dataset = Dataset.from_pandas(dataset_df)\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d483499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b89a35ba0d049e39482f2ec3450c01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c724f2dbf2246ef80d54de7fad67789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48e8d569b5a4f389743c22bf6796a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jerem\\anaconda3\\envs\\master\\Lib\\site-packages\\huggingface_hub\\lfs.py:337: UserWarning: hf_transfer is enabled but does not support uploading from bytes or BinaryIO, falling back to regular upload\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d01effc16f494ea069c75beb3b737d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d98e66a020b4e86afb271083ade2efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad65c7b986ae4150b8d6b03d57dce9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Jeremmmyyyyy/Poetry/commit/e5bf24bdee5ebba8d1a228e41dd6bff145abad7c', commit_message='Upload dataset', commit_description='', oid='e5bf24bdee5ebba8d1a228e41dd6bff145abad7c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Jeremmmyyyyy/Poetry', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Jeremmmyyyyy/Poetry'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "dataset.push_to_hub(\"Jeremmmyyyyy/Poetry\", private=False, token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ebd24",
   "metadata": {},
   "source": [
    "## This is for creating the math Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb53e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from fractions import Fraction\n",
    "\n",
    "dataset = load_dataset(\"Jiayi-Pan/Countdown-Tasks-3to4\")\n",
    "dataset_train = dataset[\"train\"].shuffle(seed=42).select(range(10000))\n",
    "dataset_test = dataset[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d81d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_countdown_expression(nums, target):\n",
    "    \"\"\"\n",
    "    Find an arithmetic expression using each number in nums exactly once that evaluates to target.\n",
    "    Operations allowed: +, -, *, /, with parentheses.\n",
    "    Uses Fraction for exact arithmetic to avoid floating-point issues.\n",
    "\n",
    "    Args:\n",
    "        nums (list of int or float): input numbers\n",
    "        target (int or float): desired target value\n",
    "\n",
    "    Returns:\n",
    "        str: a string representation of the expression that evaluates to target\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if no expression can be found\n",
    "    \"\"\"\n",
    "    # Prepare initial list of (value, expression) pairs\n",
    "    initial = [(Fraction(n), str(n)) for n in nums]\n",
    "    target_frac = Fraction(target)\n",
    "\n",
    "    def helper(pairs):\n",
    "        # If only one value remains, check if it equals the target\n",
    "        if len(pairs) == 1:\n",
    "            val, expr = pairs[0]\n",
    "            if val == target_frac:\n",
    "                return expr\n",
    "            return None\n",
    "\n",
    "        # Try all pairs of numbers\n",
    "        for i in range(len(pairs)):\n",
    "            for j in range(i + 1, len(pairs)):\n",
    "                a_val, a_expr = pairs[i]\n",
    "                b_val, b_expr = pairs[j]\n",
    "\n",
    "                # Build a new list of remaining numbers\n",
    "                rest = [pairs[k] for k in range(len(pairs)) if k not in (i, j)]\n",
    "\n",
    "                # Generate all possible operations\n",
    "                operations = [\n",
    "                    (a_val + b_val, f\"({a_expr}+{b_expr})\"),\n",
    "                    (a_val - b_val, f\"({a_expr}-{b_expr})\"),\n",
    "                    (b_val - a_val, f\"({b_expr}-{a_expr})\"),\n",
    "                    (a_val * b_val, f\"({a_expr}*{b_expr})\"),\n",
    "                ]\n",
    "\n",
    "                # Division operations, avoid division by zero\n",
    "                if b_val != 0:\n",
    "                    operations.append((a_val / b_val, f\"({a_expr}/{b_expr})\"))\n",
    "                if a_val != 0:\n",
    "                    operations.append((b_val / a_val, f\"({b_expr}/{a_expr})\"))\n",
    "\n",
    "                # Recurse on each possibility\n",
    "                for new_val, new_expr in operations:\n",
    "                    result = helper(rest + [(new_val, new_expr)])\n",
    "                    if result:\n",
    "                        val = eval(result, {\"__builtins__\": None}, {})\n",
    "                        assert abs(float(val) - float(target)) < 1e-5, f\"Invalid expression: {result}\"\n",
    "                        return result\n",
    "        return None\n",
    "\n",
    "    expression = helper(initial)\n",
    "    if expression is None:\n",
    "        raise ValueError(f\"No solution found for nums={nums} target={target}\")\n",
    "    return expression\n",
    "\n",
    "def add_gold_answer_to_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Load the HF dataset, compute the countdown solution for each example, and return a new Dataset with 'gold_answer'.\n",
    "\n",
    "    Args:\n",
    "        dataset : Hugging Face dataset\n",
    "\n",
    "    Returns:\n",
    "        datasets.Dataset: with additional 'gold_answer' column\n",
    "    \"\"\"\n",
    "    def solve(example):\n",
    "        nums = example['nums']\n",
    "        target = example['target']\n",
    "        try:\n",
    "            example['gold_answer'] = find_countdown_expression(nums, target)\n",
    "        except ValueError:\n",
    "            example['gold_answer'] = None\n",
    "        return example\n",
    "\n",
    "    new_ds = dataset.map(solve)\n",
    "    return new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74890a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = add_gold_answer_to_dataset(dataset_train)\n",
    "dataset_test = add_gold_answer_to_dataset(dataset_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
